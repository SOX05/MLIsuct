{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVGsNc0MUtLr",
        "outputId": "f2f21d98-02c8-44b8-f13e-2d85a1ddd2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Warning: Model file not found at /content/drive/MyDrive/Colab Notebooks/models/resnet_model_x50_175. Starting with a new model.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "import torchvision as tv\n",
        "from torchvision import models\n",
        "import os\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "zipped_test = '/content/drive/MyDrive/для кодов/маффины/test.zip'\n",
        "zipped_train ='/content/drive/MyDrive/для кодов/маффины/test.zip'\n",
        "z = zipfile.ZipFile(zipped_test, 'r')\n",
        "z.extractall(path='/content/dataset/test')\n",
        "z = zipfile.ZipFile(zipped_train, 'r')\n",
        "z.extractall(path='/content/dataset/train')\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "DATASET_ROOT_DIR = '/content/dataset/'\n",
        "BATCH_SIZE = 64\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "device\n",
        "\n",
        "\n",
        "transforms = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((224, 224)),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.RandomHorizontalFlip(0.5),\n",
        "])\n",
        "\n",
        "def is_valid_file(path):\n",
        "    \"\"\"Checks if a file is a valid image file and not a hidden macOS file.\"\"\"\n",
        "    return not path.startswith('._') and os.path.splitext(path)[-1].lower() in ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp']\n",
        "\n",
        "dataset = ImageFolder(root=os.path.join(DATASET_ROOT_DIR, 'train'),\n",
        "                      transform=transforms,\n",
        "                      is_valid_file=is_valid_file\n",
        "                      ) # 0 - dogs\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "train_data = DataLoader(\n",
        "                  train_dataset,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  shuffle=True,\n",
        "                  )\n",
        "test_data = DataLoader(\n",
        "                  test_dataset,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  shuffle=True,\n",
        "                  )\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        self.ep = 0\n",
        "\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "\n",
        "\n",
        "model = CustomResNet()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "actual_ep=175\n",
        "model_path = f'/content/drive/MyDrive/Colab Notebooks/models/resnet_model_x50_{actual_ep}'\n",
        "if os.path.exists(model_path):\n",
        "    model = torch.load(model_path)\n",
        "else:\n",
        "    print(f\"Warning: Model file not found at {model_path}. Starting with a new model.\")\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
        "\n",
        "\n",
        "def save_model_to_drive(model, name):\n",
        "  pth = os.path.join('/content/drive/MyDrive/Colab Notebooks/models', name)\n",
        "  torch.save(model, pth)\n",
        "\n",
        "\n",
        "def get_acc():\n",
        "  correct = 0\n",
        "  total = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2crhrvkxJ8v",
        "outputId": "c51a415a-b3fb-4dfc-a368-21fbd8561bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBdgo5D9CobC",
        "outputId": "15991dbf-ade9-475f-8ce0-ae10618d2ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Model file not found at /content/drive/MyDrive/Colab Notebooks/models/resnet_model_x50_175. Starting with a new model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [05:00<00:00,  8.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.004813789390027523\n",
            "Final accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset class with filtering\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for root, _, files in os.walk(root_dir):\n",
        "            if '__MACOSX' in root:\n",
        "                continue\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.image_paths.append(os.path.join(root, file))\n",
        "                    label = 0 if 'class0' in os.path.basename(os.path.dirname(os.path.join(root, file))) else 1\n",
        "                    self.labels.append(label)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error opening image {img_path}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "        self.ep = 0\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "\n",
        "def save_model_to_drive(model, name):\n",
        "    pth = os.path.join('/content/drive/MyDrive/Colab Notebooks/models', name)\n",
        "    torch.save(model, pth)\n",
        "\n",
        "\n",
        "def get_acc(data_loader, model, device):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for img, label in data_loader:\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "            out = model(img)\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            total += label.size(0)\n",
        "            correct += (predicted == label).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_data = CustomDataset('/content/dataset/train', transform=transform)\n",
        "test_data = CustomDataset('/content/dataset/test', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "model = CustomResNet()\n",
        "model.to(device)\n",
        "\n",
        "actual_ep = 175\n",
        "model_path = f'/content/drive/MyDrive/Colab Notebooks/models/resnet_model_x50_{actual_ep}'\n",
        "if os.path.exists(model_path):\n",
        "    model = torch.load(model_path)\n",
        "    print(f\"Model loaded from {model_path}\")\n",
        "else:\n",
        "    print(f\"Warning: Model file not found at {model_path}. Starting with a new model.\")\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    model.train()\n",
        "    for img, label in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        out = model(img)\n",
        "        loss = loss_func(out, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    model.ep += 1\n",
        "\n",
        "    print(f'Epoch {model.ep}, Loss: {loss.item()}')\n",
        "\n",
        "    if model.ep % 5 == 0:\n",
        "        acc = get_acc(test_loader, model, device)\n",
        "        print(f'Accuracy: {acc}')\n",
        "        save_model_to_drive(model, f'resnet_model_x50_{model.ep}')\n",
        "        print('Model saved!')\n",
        "\n",
        "final_acc = get_acc(test_loader, model, device)\n",
        "print(f'Final accuracy: {final_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNOhOqCaR2b6",
        "outputId": "77a40a53-e355-45f1-82f7-264300539a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "CustomResNet parameters: 11,177,538\n",
            "ResNext50_32x4d parameters: 25,028,904\n",
            "Files in /content/dataset/test: ['muffin', '__MACOSX', 'chihuahua']\n",
            "All files in directory: ['muffin', '__MACOSX', 'chihuahua']\n",
            "No valid image files found in directory: /content/dataset/test. Check the directory path and file extensions. Found: ['muffin', '__MACOSX', 'chihuahua']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision as tv\n",
        "from datetime import datetime\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        all_files = os.listdir(root)\n",
        "        print(f\"All files in directory: {all_files}\")\n",
        "\n",
        "        self.images = [\n",
        "            f for f in all_files\n",
        "            if os.path.isfile(os.path.join(root, f)) and\n",
        "            '__MACOSX' not in f and\n",
        "            any(f.lower().endswith(ext) for ext in ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.dog', '.muf'))\n",
        "        ]\n",
        "\n",
        "        if not self.images:\n",
        "            raise ValueError(\n",
        "                f\"No valid image files found in directory: {root}. \"\n",
        "                f\"Check the directory path and file extensions. Found: {all_files}\"\n",
        "            )\n",
        "\n",
        "        print(f\"Filtered images: {self.images}\")\n",
        "\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root, self.images[idx])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        return image, img_name\n",
        "\n",
        "transforms_ = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "model = CustomResNet().to(device)\n",
        "\n",
        "print(f'CustomResNet parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
        "resnext_model = models.resnext50_32x4d(pretrained=False)\n",
        "print(f'ResNext50_32x4d parameters: {sum(p.numel() for p in resnext_model.parameters()):,}')\n",
        "\n",
        "test_dataset_path = '/content/dataset/test'\n",
        "\n",
        "if not os.path.exists(test_dataset_path):\n",
        "    print(f\"The directory {test_dataset_path} does not exist.\")\n",
        "else:\n",
        "    files_in_dir = os.listdir(test_dataset_path)\n",
        "    print(f\"Files in {test_dataset_path}: {files_in_dir}\")\n",
        "\n",
        "    try:\n",
        "        d = MyDataset(test_dataset_path, transforms_)\n",
        "\n",
        "        dtldr = DataLoader(d, batch_size=1, shuffle=True)\n",
        "\n",
        "        for i, (img, img_name) in enumerate(dtldr):\n",
        "            img = img.to(device)\n",
        "            out = model(img)\n",
        "            class_label = torch.argmax(out).item()\n",
        "\n",
        "            name = 'dog' if class_label == 0 else 'muf'\n",
        "\n",
        "            base, ext = os.path.splitext(img_name[0])\n",
        "            new_name = os.path.join(test_dataset_path, f\"{name}_{i}{ext}\")\n",
        "            os.rename(img_name[0], new_name)\n",
        "            print(f\"Renamed {img_name[0]} to {new_name}\")\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "kSz2jJjSC_St"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "test_zip_path = '/content/drive/MyDrive/для кодов/маффины/test.zip'\n",
        "new_extracted_folder = '/content/dataset/new_test/'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(new_extracted_folder)\n",
        "\n",
        "extracted_folder = new_extracted_folder\n",
        "\n",
        "\n",
        "predictions = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for image_file in os.listdir(extracted_folder):\n",
        "    image_path = os.path.join(extracted_folder, image_file)\n",
        "\n",
        "\n",
        "    if os.path.isfile(image_path):\n",
        "\n",
        "        with Image.open(image_path) as img:\n",
        "\n",
        "            img = transforms(img).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                output = model(img)\n",
        "                _, predicted = torch.max(output, 1)\n",
        "\n",
        "\n",
        "            predictions.append({'ID': image_file, 'Label': predicted.item()})\n",
        "            #0=dogs  1=muffins\n",
        "\n",
        "\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "\n",
        "predictions_df.to_csv('/content/drive/MyDrive/Colab Notebooks/predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "output_csv_path = '/content/drive/My Drive/results.csv'\n",
        "\n",
        "results = [\"muffin\" if value else \"chihuahua\" for value in y_pred]\n",
        "\n",
        "labels = list(valid_files.iterdir())\n",
        "\n",
        "with open(output_csv_path, \"w\", newline=\"\") as f:\n",
        "    fieldnames = [\"ID\", \"Label\"]\n",
        "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for label, result in zip(labels, results):\n",
        "        writer.writerow({fieldnames[0]: label.name, fieldnames[1]: result})\n",
        "\n",
        "print(f\"Results saved to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "0YFwmp9K2ztj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AQNnYfKcoSH"
      },
      "source": [
        "# Новый раздел"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}